{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4D_submission.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMQdseS5HzWP",
        "colab_type": "text"
      },
      "source": [
        "# Note : THIS NOTEBOOK LOOKS DIFFERENT BECAUSE I HAVE TRIED DIFFERENT BATCH SIZES AND ADDED DROPOUTS TO THE PREVIOU NOTEBOOK ARCHITECTURE.\n",
        "\n",
        "# I AM STILL FOLLOWING THE SAME ARCHITECTURE, BUT FOR DIFFERENT BATCH SIZES,I HAVE PUT EVERYTHING IN A FUNCTION."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-OIbgY7MtFu",
        "colab_type": "text"
      },
      "source": [
        "# MNIST ASSIGNMENT:\n",
        "\n",
        "We need to:\n",
        "\n",
        "-  Follow same architecture.\n",
        "\n",
        "  - it has less than 15000 parameters\n",
        "  \n",
        "  - it achieves validation accuracy of more than 99.4% (basically print(score) should be more than 0.994)\n",
        "\n",
        "- Once done, upload the link to your Github Project to LMS.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqcSl_JVNYQC",
        "colab_type": "text"
      },
      "source": [
        "## Getting things ready!\n",
        "\n",
        "We set seed so not to lose our progress due to randomness.\n",
        "\n",
        "We later on the following libraries:\n",
        "\n",
        "1. Keras ([Keras Documentation](https://keras.io/)) :- Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. \n",
        "We import keras layers, model type Sequential (since we will be building a sequential model), and utils for plotting model and for converting single class to categorical 10 classes.\n",
        "\n",
        "2. We also import Train_test_split, Model checkpoints to save the model and ImageDataGenerator just to create a batch flow into the network. **(We are not using any augumentation techniques & other tuning parameters)**.\n",
        "\n",
        "The whole model is in itself is most basic & default."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAPEkHZuSsHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "outputId": "4040c698-72ea-486a-afb2-f30dcc7d862c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from keras.models import (Sequential,\n",
        "                          load_model)\n",
        "\n",
        "from keras.layers import (Dropout,\n",
        "                          Activation,\n",
        "                          Flatten,Conv2D,\n",
        "                          MaxPooling2D,\n",
        "                          BatchNormalization)\n",
        "\n",
        "from keras.utils import (np_utils,\n",
        "                         plot_model)\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import datetime\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "## Load pre-shuffled MNIST data into Train set and Test set\n",
        "\n",
        "After loading the Train and Test sets, we initially plot any one image from the Train set and see how the images really look like. \n",
        "\n",
        "We then reshape our data into 28x28x1, which would be input to our network. Here 28x28 is the image Height x Width and 1 is the number of channels. We also standardise our pixel (range: 0-255) values so as to obtain normally distributed pixel values between range 0-1, and also due to computational reasons.\n",
        "\n",
        "We explore total number of digits on each class and then, convert our target variable into categorical 10 classes output, where each bit is set to 1 corresponding to the actual digit value. \n",
        "\n",
        "- Example: if the digit value is 6, then the 6th column is set to 1 and the rest 9 columns are set to 0.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "outputId": "c5c3dfd3-80eb-4a38-ec48-8cd33134e39c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "d6752a60-8cf3-422b-8170-43c5d12f3e19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f81bad2d400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRfiBoAg/EBThB4Ii/EBQhB8I6v8AG8x2aarNGp8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "e46e6dc7-f3fe-4ccf-8131-7b7d7ec8f08c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gKBi1deTdve",
        "colab_type": "text"
      },
      "source": [
        "#### Exploratary Data Analysis : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "894mVykgTlUM",
        "colab_type": "code",
        "outputId": "4f5fe2b3-34a7-4f44-fb90-6f918f0e1d80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "sns.countplot(y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f81bad2dac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAD8CAYAAABgmUMCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJEmd/H9Jj4YNWIbSKAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ4jBjSMTlQx",
        "colab_type": "code",
        "outputId": "006a36c2-3f4a-46d3-fe95-3dbf710bc95a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "sns.countplot(y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f81bacd7f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAD8CAYAAABgmUMCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "1ba214fa-a781-437b-8bed-88c0303281fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "Y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGhQSY_ainpC",
        "colab_type": "text"
      },
      "source": [
        "### After getting very good accuracy in the previous notebook, now lets reduce the gap and check this model and finally test the validation accuracy.\n",
        "\n",
        "### We are adding dropouts because in the previous notebook, we have see training accuracy almost touched 100%.\n",
        "\n",
        "### This is the final notebook.\n",
        "\n",
        "The architecture is:\n",
        "\n",
        "INPUT>>CN>>BN>>CN>>BN>>MP>>DP>>CN>>BN>>CN>>BN>>CN>>BN>>MP>>DP>>CN>>BN>>CN>>FLATTERN>>OUTPUT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osKqT73Q9JJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def __model__(load_model=False, model_name=''):\n",
        "  \n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(16, kernel_size = 3, activation='relu',name=\"Conv2D_1\", input_shape = (28, 28, 1)))\n",
        "  model.add(BatchNormalization(name=\"BatchNormalization_1\"))\n",
        "  model.add(Conv2D(30, kernel_size = 3,name=\"Conv2D_2\", activation='relu'))\n",
        "  model.add(BatchNormalization(name=\"BatchNormalization_2\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2),name=\"MaxPool2D_1\"))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  model.add(Conv2D(12, kernel_size = 3,name=\"Conv2D_3\", activation='relu'))\n",
        "  model.add(BatchNormalization(name=\"BatchNormalization_3\"))\n",
        "  model.add(Conv2D(12, kernel_size = 3,name=\"Conv2D_4\", activation='relu'))\n",
        "  model.add(BatchNormalization(name=\"BatchNormalization_4\"))\n",
        "  model.add(Conv2D(29, kernel_size = 3,name=\"Conv2D_5\", activation='relu'))\n",
        "  model.add(BatchNormalization(name=\"BatchNormalization_5\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2),name=\"MaxPool2D_2\"))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  model.add(Conv2D(18,kernel_size=(1,1),name=\"Conv2D_6\",activation='relu'))\n",
        "  model.add(BatchNormalization(name=\"BatchNormalization_6\"))\n",
        "  model.add(Conv2D(10, kernel_size = 3,name=\"Conv2D_7\"))\n",
        "  model.add(Flatten())\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  if load_model:\n",
        "    model.load_weights(model_name)\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "  \n",
        "  print('\\nTOTAL NUMBER OF PARAMETERS : ',model.count_params(),'\\n\\n')\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzdAYg1k9K7Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cnn_fit(X_train,y_train,X_test,y_test, batch_size=128, epochs = 10, verbose = 1, cnn=0):\n",
        "  model = __model__()\n",
        "  \n",
        "  datagen = ImageDataGenerator()\n",
        "  \n",
        "  file_name_model = (\"model_\"+str(cnn)+\".hdf5\")\n",
        "  checkpointer = ModelCheckpoint(monitor='val_acc',\n",
        "                                   filepath=(\"./\"+file_name_model),\n",
        "                                   verbose=0, save_best_only=True, mode='max')\n",
        "    \n",
        "  \n",
        "  history = model.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),\n",
        "                              epochs = epochs, \n",
        "                              callbacks=[checkpointer],steps_per_epoch=5000,\n",
        "                              validation_steps=6000,\n",
        "                              validation_data = datagen.flow(X_test,y_test,batch_size=batch_size),\n",
        "                              verbose = verbose)\n",
        "\n",
        "  return(history, model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7L4EfED4iumC",
        "colab_type": "code",
        "outputId": "8086f9b0-16a9-4799-f5be-78da767d54cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2757
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "total_cnn=list()\n",
        "result=0\n",
        "selection_threshold_score = 0.9940 ## Aiming for Higher Accuracy !\n",
        "cnn=0\n",
        "\n",
        "print(\"LETS AIM FOR ACCURACY 99.40...\")\n",
        "\n",
        "for batch_size in [32,64,128,256]:\n",
        "  print(\"=\"*100)\n",
        "  print('START WITH BATCH SIZE : ', batch_size)\n",
        "\n",
        "  cnn+=1\n",
        "  time_start = datetime.datetime.now()\n",
        "  \n",
        "  history,model = cnn_fit(X_train, Y_train, X_test, Y_test, \n",
        "                           batch_size=batch_size, epochs=10, verbose=1, cnn=cnn)\n",
        "\n",
        "  print('\\nMODEL STATS : '\\\n",
        "          '| LAST TRAINING ACCURACY =', round(history.history['acc'][-1],5), \\\n",
        "          '| MAXIMUM VALIDATION ACCURACY =', round(max(history.history['val_acc']),5),\\\n",
        "          '| TOTAL TIME TAKEN TO COMPLETE : ', (datetime.datetime.now() - time_start),'\\n')\n",
        "\n",
        "  K.clear_session()\n",
        "  del model\n",
        "\n",
        "  model = __model__(load_model=True, model_name='model_'+str(cnn)+'.hdf5')\n",
        "\n",
        "  score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "  \n",
        "  # Models selection\n",
        "  if round(score[1], 5) >= selection_threshold_score:\n",
        "    total_cnn.append(cnn)\n",
        "    print('\\nSCORE CROSSED THRESHOLD :: 0.9940 < ', round(score[1],5),'\\n')\n",
        "    print('SCORE AT BATCH SIZE ',batch_size,' IS : ',score)\n",
        "  else:\n",
        "    print(' - SKIPPING SCORE SINCE NOT ENOUGH TO CROSS THRESHOLD :: 0.9940 > ', round(score[1],5),'\\n')\n",
        "\n",
        "  K.clear_session()\n",
        "  del model\n",
        "  del history\n",
        "  print('='*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LETS AIM FOR ACCURACY 99.40...\n",
            "====================================================================================================\n",
            "START WITH BATCH SIZE :  32\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "\n",
            "TOTAL NUMBER OF PARAMETERS :  14869 \n",
            "\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/10\n",
            "5000/5000 [==============================] - 72s 14ms/step - loss: 0.1243 - acc: 0.9616 - val_loss: 0.0429 - val_acc: 0.9868\n",
            "Epoch 2/10\n",
            "5000/5000 [==============================] - 69s 14ms/step - loss: 0.0430 - acc: 0.9864 - val_loss: 0.0270 - val_acc: 0.9912\n",
            "Epoch 3/10\n",
            "5000/5000 [==============================] - 68s 14ms/step - loss: 0.0341 - acc: 0.9891 - val_loss: 0.0346 - val_acc: 0.9902\n",
            "Epoch 4/10\n",
            "5000/5000 [==============================] - 68s 14ms/step - loss: 0.0276 - acc: 0.9911 - val_loss: 0.0284 - val_acc: 0.9906\n",
            "Epoch 5/10\n",
            "5000/5000 [==============================] - 68s 14ms/step - loss: 0.0245 - acc: 0.9920 - val_loss: 0.0247 - val_acc: 0.9927\n",
            "Epoch 6/10\n",
            "5000/5000 [==============================] - 70s 14ms/step - loss: 0.0218 - acc: 0.9928 - val_loss: 0.0239 - val_acc: 0.9924\n",
            "Epoch 7/10\n",
            "5000/5000 [==============================] - 67s 13ms/step - loss: 0.0201 - acc: 0.9936 - val_loss: 0.0257 - val_acc: 0.9926\n",
            "Epoch 8/10\n",
            "5000/5000 [==============================] - 68s 14ms/step - loss: 0.0185 - acc: 0.9937 - val_loss: 0.0244 - val_acc: 0.9933\n",
            "Epoch 9/10\n",
            "5000/5000 [==============================] - 68s 14ms/step - loss: 0.0173 - acc: 0.9942 - val_loss: 0.0279 - val_acc: 0.9930\n",
            "Epoch 10/10\n",
            "5000/5000 [==============================] - 68s 14ms/step - loss: 0.0157 - acc: 0.9948 - val_loss: 0.0228 - val_acc: 0.9936\n",
            "\n",
            "MODEL STATS : | LAST TRAINING ACCURACY = 0.99478 | MAXIMUM VALIDATION ACCURACY = 0.9936 | TOTAL TIME TAKEN TO COMPLETE :  0:11:30.940999 \n",
            "\n",
            "\n",
            "TOTAL NUMBER OF PARAMETERS :  14869 \n",
            "\n",
            "\n",
            " - SKIPPING SCORE SINCE NOT ENOUGH TO CROSS THRESHOLD :: 0.9940 >  0.9936 \n",
            "\n",
            "====================================================================================================\n",
            "====================================================================================================\n",
            "START WITH BATCH SIZE :  64\n",
            "\n",
            "TOTAL NUMBER OF PARAMETERS :  14869 \n",
            "\n",
            "\n",
            "Epoch 1/10\n",
            "5000/5000 [==============================] - 73s 15ms/step - loss: 0.0963 - acc: 0.9703 - val_loss: 0.0295 - val_acc: 0.9902\n",
            "Epoch 2/10\n",
            "5000/5000 [==============================] - 70s 14ms/step - loss: 0.0295 - acc: 0.9905 - val_loss: 0.0290 - val_acc: 0.9902\n",
            "Epoch 3/10\n",
            "5000/5000 [==============================] - 70s 14ms/step - loss: 0.0220 - acc: 0.9928 - val_loss: 0.0242 - val_acc: 0.9920\n",
            "Epoch 4/10\n",
            "5000/5000 [==============================] - 71s 14ms/step - loss: 0.0174 - acc: 0.9943 - val_loss: 0.0258 - val_acc: 0.9915\n",
            "Epoch 5/10\n",
            "5000/5000 [==============================] - 72s 14ms/step - loss: 0.0150 - acc: 0.9949 - val_loss: 0.0250 - val_acc: 0.9920\n",
            "Epoch 6/10\n",
            "5000/5000 [==============================] - 70s 14ms/step - loss: 0.0131 - acc: 0.9956 - val_loss: 0.0259 - val_acc: 0.9927\n",
            "Epoch 7/10\n",
            "5000/5000 [==============================] - 71s 14ms/step - loss: 0.0116 - acc: 0.9961 - val_loss: 0.0239 - val_acc: 0.9937\n",
            "Epoch 8/10\n",
            "5000/5000 [==============================] - 71s 14ms/step - loss: 0.0106 - acc: 0.9963 - val_loss: 0.0269 - val_acc: 0.9931\n",
            "Epoch 9/10\n",
            "5000/5000 [==============================] - 72s 14ms/step - loss: 0.0095 - acc: 0.9966 - val_loss: 0.0285 - val_acc: 0.9932\n",
            "Epoch 10/10\n",
            "5000/5000 [==============================] - 73s 15ms/step - loss: 0.0088 - acc: 0.9970 - val_loss: 0.0284 - val_acc: 0.9935\n",
            "\n",
            "MODEL STATS : | LAST TRAINING ACCURACY = 0.997 | MAXIMUM VALIDATION ACCURACY = 0.99369 | TOTAL TIME TAKEN TO COMPLETE :  0:11:54.631569 \n",
            "\n",
            "\n",
            "TOTAL NUMBER OF PARAMETERS :  14869 \n",
            "\n",
            "\n",
            " - SKIPPING SCORE SINCE NOT ENOUGH TO CROSS THRESHOLD :: 0.9940 >  0.9937 \n",
            "\n",
            "====================================================================================================\n",
            "====================================================================================================\n",
            "START WITH BATCH SIZE :  128\n",
            "\n",
            "TOTAL NUMBER OF PARAMETERS :  14869 \n",
            "\n",
            "\n",
            "Epoch 1/10\n",
            "5000/5000 [==============================] - 86s 17ms/step - loss: 0.0734 - acc: 0.9772 - val_loss: 0.0276 - val_acc: 0.9903\n",
            "Epoch 2/10\n",
            "5000/5000 [==============================] - 85s 17ms/step - loss: 0.0198 - acc: 0.9936 - val_loss: 0.0206 - val_acc: 0.9938\n",
            "Epoch 3/10\n",
            "5000/5000 [==============================] - 85s 17ms/step - loss: 0.0140 - acc: 0.9953 - val_loss: 0.0211 - val_acc: 0.9940\n",
            "Epoch 4/10\n",
            "5000/5000 [==============================] - 87s 17ms/step - loss: 0.0109 - acc: 0.9962 - val_loss: 0.0261 - val_acc: 0.9928\n",
            "Epoch 5/10\n",
            "5000/5000 [==============================] - 81s 16ms/step - loss: 0.0090 - acc: 0.9969 - val_loss: 0.0246 - val_acc: 0.9939\n",
            "Epoch 6/10\n",
            "5000/5000 [==============================] - 85s 17ms/step - loss: 0.0079 - acc: 0.9972 - val_loss: 0.0225 - val_acc: 0.9946\n",
            "Epoch 7/10\n",
            "5000/5000 [==============================] - 86s 17ms/step - loss: 0.0072 - acc: 0.9975 - val_loss: 0.0219 - val_acc: 0.9946\n",
            "Epoch 8/10\n",
            "5000/5000 [==============================] - 85s 17ms/step - loss: 0.0065 - acc: 0.9978 - val_loss: 0.0241 - val_acc: 0.9942\n",
            "Epoch 9/10\n",
            "5000/5000 [==============================] - 85s 17ms/step - loss: 0.0059 - acc: 0.9981 - val_loss: 0.0251 - val_acc: 0.9938\n",
            "Epoch 10/10\n",
            "5000/5000 [==============================] - 85s 17ms/step - loss: 0.0056 - acc: 0.9981 - val_loss: 0.0260 - val_acc: 0.9943\n",
            "\n",
            "MODEL STATS : | LAST TRAINING ACCURACY = 0.99811 | MAXIMUM VALIDATION ACCURACY = 0.9946 | TOTAL TIME TAKEN TO COMPLETE :  0:14:12.975444 \n",
            "\n",
            "\n",
            "TOTAL NUMBER OF PARAMETERS :  14869 \n",
            "\n",
            "\n",
            "\n",
            "SCORE CROSSED THRESHOLD :: 0.9940 <  0.9946 \n",
            "\n",
            "SCORE AT BATCH SIZE  128  IS :  [0.021943003207898982, 0.9946]\n",
            "====================================================================================================\n",
            "====================================================================================================\n",
            "START WITH BATCH SIZE :  256\n",
            "\n",
            "TOTAL NUMBER OF PARAMETERS :  14869 \n",
            "\n",
            "\n",
            "Epoch 1/10\n",
            "5000/5000 [==============================] - 109s 22ms/step - loss: 0.0587 - acc: 0.9818 - val_loss: 0.0222 - val_acc: 0.9931\n",
            "Epoch 2/10\n",
            "5000/5000 [==============================] - 106s 21ms/step - loss: 0.0133 - acc: 0.9955 - val_loss: 0.0225 - val_acc: 0.9933\n",
            "Epoch 3/10\n",
            "5000/5000 [==============================] - 106s 21ms/step - loss: 0.0090 - acc: 0.9969 - val_loss: 0.0245 - val_acc: 0.9935\n",
            "Epoch 4/10\n",
            "5000/5000 [==============================] - 103s 21ms/step - loss: 0.0070 - acc: 0.9976 - val_loss: 0.0274 - val_acc: 0.9930\n",
            "Epoch 5/10\n",
            "5000/5000 [==============================] - 104s 21ms/step - loss: 0.0059 - acc: 0.9980 - val_loss: 0.0312 - val_acc: 0.9929\n",
            "Epoch 6/10\n",
            "5000/5000 [==============================] - 106s 21ms/step - loss: 0.0051 - acc: 0.9982 - val_loss: 0.0295 - val_acc: 0.9934\n",
            "Epoch 7/10\n",
            "5000/5000 [==============================] - 105s 21ms/step - loss: 0.0046 - acc: 0.9985 - val_loss: 0.0282 - val_acc: 0.9946\n",
            "Epoch 8/10\n",
            "5000/5000 [==============================] - 105s 21ms/step - loss: 0.0041 - acc: 0.9986 - val_loss: 0.0306 - val_acc: 0.9935\n",
            "Epoch 9/10\n",
            "5000/5000 [==============================] - 106s 21ms/step - loss: 0.0039 - acc: 0.9987 - val_loss: 0.0355 - val_acc: 0.9921\n",
            "Epoch 10/10\n",
            "5000/5000 [==============================] - 106s 21ms/step - loss: 0.0036 - acc: 0.9988 - val_loss: 0.0311 - val_acc: 0.9942\n",
            "\n",
            "MODEL STATS : | LAST TRAINING ACCURACY = 0.99879 | MAXIMUM VALIDATION ACCURACY = 0.9946 | TOTAL TIME TAKEN TO COMPLETE :  0:17:38.934062 \n",
            "\n",
            "\n",
            "TOTAL NUMBER OF PARAMETERS :  14869 \n",
            "\n",
            "\n",
            "\n",
            "SCORE CROSSED THRESHOLD :: 0.9940 <  0.9946 \n",
            "\n",
            "SCORE AT BATCH SIZE  256  IS :  [0.028222208515226294, 0.9946]\n",
            "====================================================================================================\n",
            "CPU times: user 1h 11min 47s, sys: 6min 46s, total: 1h 18min 33s\n",
            "Wall time: 55min 24s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwHSCq7KMrzd",
        "colab_type": "text"
      },
      "source": [
        "## THIS ARCHITECTURE WAS GOOD AND HENCE WE GOT GOOD 99.4+% VALIDATION ACCURACY ON ALMOST ALL THE DIFFERENT BATCH SIZES."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkX8JMv79q9r",
        "colab_type": "code",
        "outputId": "cfce439f-7138-44a1-ed71-bc4d460af7d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print('MAXIMUM VALIDATION ACCURACY WITH BATCH SIZE 32 IS : 99.37')\n",
        "print('MAXIMUM VALIDATION ACCURACY WITH BATCH SIZE 64 IS : 99.37')\n",
        "print('MAXIMUM VALIDATION ACCURACY WITH BATCH SIZE 128 IS : 99.46')\n",
        "print('MAXIMUM VALIDATION ACCURACY WITH BATCH SIZE 256 IS : 99.46')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAXIMUM VALIDATION ACCURACY WITH BATCH SIZE 32 IS : 99.37\n",
            "MAXIMUM VALIDATION ACCURACY WITH BATCH SIZE 64 IS : 99.37\n",
            "MAXIMUM VALIDATION ACCURACY WITH BATCH SIZE 128 IS : 99.46\n",
            "MAXIMUM VALIDATION ACCURACY WITH BATCH SIZE 256 IS : 99.46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sf7dU3ONJoL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}