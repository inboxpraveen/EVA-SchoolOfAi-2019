{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 18 - Shuffle Net.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDphMpfqybsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tiny-imagenet dataset has 200 categories\n",
        "# and all images have 64x64 size,\n",
        "# but i use 56x56 images because i do\n",
        "# data augmentation by making random crops\n",
        "IMAGE_SIZE = 56\n",
        "NUM_CLASSES = 200\n",
        "# if input image has spatial size [56, 56]\n",
        "# then spatial size before the global average pooling is [4, 4]\n",
        "\n",
        "\n",
        "BATCH_NORM_MOMENTUM = 0.1\n",
        "# it differs from the default Tensorflow value (0.9),\n",
        "# sometimes right momentum value is very important\n",
        "\n",
        "N_SHUFFLE_UNITS = (1, 3, 1)\n",
        "# number of shuffle units of stride 1 in each stage,\n",
        "# in the original paper: [3, 7, 3].\n",
        "\n",
        "# number of layers that the network will have:\n",
        "# (sum(N_SHUFFLE_UNITS) + 3)*3 + 1 + 1\n",
        "\n",
        "# stride in the first convolution layer:\n",
        "# in the original paper they are using stride=2\n",
        "# but because i use small 64x64 images i chose stride=1\n",
        "FIRST_STRIDE = 1\n",
        "\n",
        "\n",
        "# optimizer settings\n",
        "MOMENTUM = 0.9\n",
        "USE_NESTEROV = True\n",
        "LR_REDUCE_FACTOR = 0.1\n",
        "\n",
        "\n",
        "# input pipeline settings.\n",
        "# you need to tweak these numbers for your system,\n",
        "# it can accelerate training\n",
        "SHUFFLE_BUFFER_SIZE = 10000\n",
        "PREFETCH_BUFFER_SIZE = 1000\n",
        "NUM_THREADS = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMvNI35mJHR1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "4c99c53a-3c63-468c-cd92-6d0b7aab1701"
      },
      "source": [
        "import tensorflow as tf\n",
        "import math\n",
        "\n",
        "def _channel_shuffle(X, groups):\n",
        "    height, width, in_channels = X.shape.as_list()[1:]\n",
        "    in_channels_per_group = int(in_channels/groups)\n",
        "\n",
        "    # reshape\n",
        "    shape = tf.stack([-1, height, width, groups, in_channels_per_group])\n",
        "    X = tf.reshape(X, shape)\n",
        "\n",
        "    # transpose\n",
        "    X = tf.transpose(X, [0, 1, 2, 4, 3])\n",
        "\n",
        "    # reshape\n",
        "    shape = tf.stack([-1, height, width, in_channels])\n",
        "    X = tf.reshape(X, shape)\n",
        "\n",
        "    return X\n",
        "\n",
        "\n",
        "def _mapping(\n",
        "        X, is_training, num_classes=200,\n",
        "        groups=3, dropout=0.5,\n",
        "        complexity_scale_factor=0.75):\n",
        "    \"\"\"A ShuffleNet implementation.\n",
        "    Arguments:\n",
        "        X: A float tensor with shape [batch_size, image_height, image_width, 3].\n",
        "        is_training: A boolean, whether the network is in the training mode.\n",
        "        num_classes: An integer.\n",
        "        groups: An integer, number of groups in group convolutions,\n",
        "            only possible values are: 1, 2, 3, 4, 8.\n",
        "        dropout: A floar number, dropout rate before the last linear layer.\n",
        "        complexity_scale_factor: A floar number, to customize the network\n",
        "            to a desired complexity you can apply a scale factor,\n",
        "            in the original paper they are considering\n",
        "            scale factor values: 0.25, 0.5, 1.0.\n",
        "            It determines the width of the network.\n",
        "    Returns:\n",
        "        A float tensor with shape [batch_size, num_classes].\n",
        "    \"\"\"\n",
        "\n",
        "    # 'out_channels' equals to second stage's number of output channels\n",
        "    if groups == 1:\n",
        "        out_channels = 144\n",
        "    elif groups == 2:\n",
        "        out_channels = 200\n",
        "    elif groups == 3:\n",
        "        out_channels = 240\n",
        "    elif groups == 4:\n",
        "        out_channels = 272\n",
        "    elif groups == 8:\n",
        "        out_channels = 384\n",
        "    # all 'out_channels' are divisible by corresponding 'groups'\n",
        "\n",
        "    # if you want you can decrease network's width\n",
        "    out_channels = int(out_channels * complexity_scale_factor)\n",
        "\n",
        "    with tf.variable_scope('features'):\n",
        "\n",
        "        with tf.variable_scope('stage1'):\n",
        "\n",
        "            with tf.variable_scope('conv1'):\n",
        "                result = _conv(X, 24, kernel=3, stride=FIRST_STRIDE)\n",
        "\n",
        "            result = _batch_norm(result, is_training)\n",
        "            result = _nonlinearity(result)\n",
        "            # in the original paper they are not using batch_norm and relu here\n",
        "\n",
        "            result = _max_pooling(result)\n",
        "\n",
        "        with tf.variable_scope('stage2'):\n",
        "\n",
        "            with tf.variable_scope('unit1'):\n",
        "                result = _first_shufflenet_unit(\n",
        "                    result, is_training, groups, out_channels\n",
        "                )\n",
        "\n",
        "            for i in range(N_SHUFFLE_UNITS[0]):\n",
        "                with tf.variable_scope('unit' + str(i + 2)):\n",
        "                    result = _shufflenet_unit(result, is_training, groups)\n",
        "\n",
        "            # number of channels in 'result' is out_channels\n",
        "\n",
        "        with tf.variable_scope('stage3'):\n",
        "\n",
        "            with tf.variable_scope('unit1'):\n",
        "                result = _shufflenet_unit(result, is_training, groups, stride=2)\n",
        "\n",
        "            for i in range(N_SHUFFLE_UNITS[1]):\n",
        "                with tf.variable_scope('unit' + str(i + 2)):\n",
        "                    result = _shufflenet_unit(result, is_training, groups)\n",
        "\n",
        "            # number of channels in 'result' is 2*out_channels\n",
        "\n",
        "        with tf.variable_scope('stage4'):\n",
        "\n",
        "            with tf.variable_scope('unit1'):\n",
        "                result = _shufflenet_unit(result, is_training, groups, stride=2)\n",
        "\n",
        "            for i in range(N_SHUFFLE_UNITS[2]):\n",
        "                with tf.variable_scope('unit' + str(i + 2)):\n",
        "                    result = _shufflenet_unit(result, is_training, groups)\n",
        "\n",
        "            # number of channels in 'result' is 4*out_channels\n",
        "\n",
        "    with tf.variable_scope('classifier'):\n",
        "        result = _global_average_pooling(result)\n",
        "\n",
        "        result = _dropout(result, is_training, dropout)\n",
        "        # in the original paper they are not using dropout here\n",
        "\n",
        "        logits = _affine(result, num_classes)\n",
        "\n",
        "    return logits\n",
        "\n",
        "\n",
        "def _nonlinearity(X):\n",
        "    return tf.nn.relu(X, name='ReLU')\n",
        "\n",
        "\n",
        "def _dropout(X, is_training, rate=0.5):\n",
        "    keep_prob = tf.constant(\n",
        "        1.0 - rate, tf.float32,\n",
        "        [], 'keep_prob'\n",
        "    )\n",
        "    result = tf.cond(\n",
        "        is_training,\n",
        "        lambda: tf.nn.dropout(X, keep_prob),\n",
        "        lambda: tf.identity(X),\n",
        "        name='dropout'\n",
        "    )\n",
        "    return result\n",
        "\n",
        "\n",
        "def _batch_norm(X, is_training):\n",
        "    return tf.layers.batch_normalization(\n",
        "        X, scale=False, center=True,\n",
        "        momentum=BATCH_NORM_MOMENTUM,\n",
        "        training=is_training, fused=True\n",
        "    )\n",
        "\n",
        "\n",
        "def _global_average_pooling(X):\n",
        "    return tf.reduce_mean(\n",
        "        X, axis=[1, 2],\n",
        "        name='global_average_pooling'\n",
        "    )\n",
        "\n",
        "\n",
        "def _max_pooling(X):\n",
        "    return tf.nn.max_pool(\n",
        "        X, [1, 3, 3, 1], [1, 2, 2, 1], 'SAME',\n",
        "        name='max_pooling'\n",
        "    )\n",
        "\n",
        "\n",
        "def _avg_pooling(X):\n",
        "    return tf.nn.avg_pool(\n",
        "        X, [1, 3, 3, 1], [1, 2, 2, 1], 'SAME',\n",
        "        name='avg_pooling'\n",
        "    )\n",
        "\n",
        "\n",
        "def _conv(X, filters, kernel=3, stride=1):\n",
        "\n",
        "    in_channels = X.shape.as_list()[-1]\n",
        "\n",
        "    # kaiming uniform initialization\n",
        "    maxval = math.sqrt(6.0/in_channels)\n",
        "\n",
        "    K = tf.get_variable(\n",
        "        'kernel', [kernel, kernel, in_channels, filters],\n",
        "        tf.float32, tf.random_uniform_initializer(-maxval, maxval)\n",
        "    )\n",
        "\n",
        "    b = tf.get_variable(\n",
        "        'bias', [filters], tf.float32,\n",
        "        tf.zeros_initializer()\n",
        "    )\n",
        "\n",
        "    return tf.nn.bias_add(\n",
        "        tf.nn.conv2d(X, K, [1, stride, stride, 1], 'SAME'), b\n",
        "    )\n",
        "\n",
        "\n",
        "def _group_conv(X, filters, groups, kernel=1, stride=1):\n",
        "\n",
        "    in_channels = X.shape.as_list()[3]\n",
        "    in_channels_per_group = int(in_channels/groups)\n",
        "    filters_per_group = int(filters/groups)\n",
        "\n",
        "    # kaiming uniform initialization\n",
        "    maxval = math.sqrt(6.0/in_channels_per_group)\n",
        "\n",
        "    K = tf.get_variable(\n",
        "        'kernel', [kernel, kernel, in_channels_per_group, filters],\n",
        "        tf.float32, tf.random_uniform_initializer(-maxval, maxval)\n",
        "    )\n",
        "\n",
        "    # split channels\n",
        "    X_channel_splits = tf.split(X, [in_channels_per_group]*groups, axis=3)\n",
        "    K_filter_splits = tf.split(K, [filters_per_group]*groups, axis=3)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # do convolution for each split\n",
        "    for i in range(groups):\n",
        "        X_split = X_channel_splits[i]\n",
        "        K_split = K_filter_splits[i]\n",
        "        results += [tf.nn.conv2d(X_split, K_split, [1, stride, stride, 1], 'SAME')]\n",
        "\n",
        "    return tf.concat(results, 3)\n",
        "\n",
        "\n",
        "def _depthwise_conv(X, kernel=3, stride=1):\n",
        "\n",
        "    in_channels = X.shape.as_list()[3]\n",
        "\n",
        "    # kaiming uniform initialization\n",
        "    maxval = math.sqrt(6.0/in_channels)\n",
        "\n",
        "    W = tf.get_variable(\n",
        "        'depthwise_kernel', [kernel, kernel, in_channels, 1],\n",
        "        tf.float32, tf.random_uniform_initializer(-maxval, maxval)\n",
        "    )\n",
        "\n",
        "    return tf.nn.depthwise_conv2d(X, W, [1, stride, stride, 1], 'SAME')\n",
        "\n",
        "\n",
        "def _shufflenet_unit(X, is_training, groups=3, stride=1):\n",
        "\n",
        "    in_channels = X.shape.as_list()[3]\n",
        "    result = X\n",
        "\n",
        "    with tf.variable_scope('g_conv_1'):\n",
        "        result = _group_conv(result, in_channels, groups)\n",
        "        result = _batch_norm(result, is_training)\n",
        "        result = _nonlinearity(result)\n",
        "\n",
        "    with tf.variable_scope('channel_shuffle_2'):\n",
        "        result = _channel_shuffle(result, groups)\n",
        "\n",
        "    with tf.variable_scope('dw_conv_3'):\n",
        "        result = _depthwise_conv(result, stride=stride)\n",
        "        result = _batch_norm(result, is_training)\n",
        "\n",
        "    with tf.variable_scope('g_conv_4'):\n",
        "        result = _group_conv(result, in_channels, groups)\n",
        "        result = _batch_norm(result, is_training)\n",
        "\n",
        "    if stride < 2:\n",
        "        result = tf.add(result, X)\n",
        "    else:\n",
        "        X = _avg_pooling(X)\n",
        "        result = tf.concat([result, X], 3)\n",
        "\n",
        "    result = _nonlinearity(result)\n",
        "    return result\n",
        "\n",
        "\n",
        "# first shufflenet unit is different from the rest\n",
        "def _first_shufflenet_unit(X, is_training, groups, out_channels):\n",
        "\n",
        "    in_channels = X.shape.as_list()[3]\n",
        "    result = X\n",
        "    out_channels -= in_channels\n",
        "\n",
        "    with tf.variable_scope('g_conv_1'):\n",
        "        result = _group_conv(result, out_channels, groups=1)\n",
        "        result = _batch_norm(result, is_training)\n",
        "        result = _nonlinearity(result)\n",
        "\n",
        "    with tf.variable_scope('dw_conv_2'):\n",
        "        result = _depthwise_conv(result, stride=2)\n",
        "        result = _batch_norm(result, is_training)\n",
        "\n",
        "    with tf.variable_scope('g_conv_3'):\n",
        "        result = _group_conv(result, out_channels, groups)\n",
        "        result = _batch_norm(result, is_training)\n",
        "\n",
        "    X = _avg_pooling(X)\n",
        "    result = tf.concat([result, X], 3)\n",
        "    result = _nonlinearity(result)\n",
        "    return result\n",
        "\n",
        "\n",
        "def _affine(X, size):\n",
        "    input_dim = X.shape.as_list()[1]\n",
        "\n",
        "    # kaiming uniform initialization\n",
        "    maxval = math.sqrt(6.0/input_dim)\n",
        "\n",
        "    W = tf.get_variable(\n",
        "        'kernel', [input_dim, size], tf.float32,\n",
        "        tf.random_uniform_initializer(-maxval, maxval)\n",
        "    )\n",
        "\n",
        "    b = tf.get_variable(\n",
        "        'bias', [size], tf.float32,\n",
        "        tf.zeros_initializer()\n",
        "    )\n",
        "\n",
        "    return tf.nn.bias_add(tf.matmul(X, W), b)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2kYETS8JKGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def _get_data(num_classes, image_size):\n",
        "    \"\"\"Get images and targets in batches.\n",
        "    Training data is augmented with random crops,\n",
        "    flips, and color manipulations.\n",
        "    When evaluating center crop is made.\n",
        "    Arguments:\n",
        "        num_classes: An integer.\n",
        "        image_size: An integer, it is assumed that\n",
        "            image_width = image_height = image_size.\n",
        "    Returns:\n",
        "        A dict with the following keys:\n",
        "            'init_data': An op, initialize data sources and batch size.\n",
        "            'train_init': An op, initialize train data iterator.\n",
        "            'val_init': An op, initialize validation data iterator.\n",
        "            'x_batch': A float tensor with shape [batch_size, image_size, image_size, 3],\n",
        "                images have pixel values in range [0, 1].\n",
        "            'y_batch': A float tensor with shape [batch_size, num_classes],\n",
        "                targets are one-hot encoded.\n",
        "    \"\"\"\n",
        "\n",
        "    batch_size = tf.Variable(\n",
        "        tf.placeholder(tf.int64, [], 'batch_size'),\n",
        "        trainable=False, collections=[]\n",
        "    )\n",
        "    train_file = tf.Variable(\n",
        "        tf.placeholder(tf.string, [], 'train_file'),\n",
        "        trainable=False, collections=[]\n",
        "    )\n",
        "    val_file = tf.Variable(\n",
        "        tf.placeholder(tf.string, [], 'val_file'),\n",
        "        trainable=False, collections=[]\n",
        "    )\n",
        "    init_data = tf.variables_initializer([batch_size, train_file, val_file])\n",
        "\n",
        "    train_dataset = tf.data.TFRecordDataset(train_file)\n",
        "    train_dataset = train_dataset.map(\n",
        "        lambda x: _parse_and_preprocess(x, image_size, augmentation=True),\n",
        "        num_parallel_calls=NUM_THREADS\n",
        "    ).prefetch(PREFETCH_BUFFER_SIZE)\n",
        "\n",
        "    train_dataset = train_dataset.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n",
        "    train_dataset = train_dataset.batch(batch_size)\n",
        "    train_dataset = train_dataset.repeat()\n",
        "\n",
        "    val_dataset = tf.data.TFRecordDataset(val_file)\n",
        "    val_dataset = val_dataset.map(\n",
        "        lambda x: _parse_and_preprocess(x, image_size)\n",
        "    )\n",
        "    val_dataset = val_dataset.batch(batch_size)\n",
        "    val_dataset = val_dataset.repeat()\n",
        "\n",
        "    iterator = tf.data.Iterator.from_structure(\n",
        "        train_dataset.output_types,\n",
        "        train_dataset.output_shapes\n",
        "    )\n",
        "    train_init = iterator.make_initializer(train_dataset)\n",
        "    val_init = iterator.make_initializer(val_dataset)\n",
        "\n",
        "    x_batch, y_batch = iterator.get_next()\n",
        "    y_batch = tf.one_hot(y_batch, num_classes, axis=1, dtype=tf.float32)\n",
        "\n",
        "    data = {\n",
        "        'init_data': init_data,\n",
        "        'train_init': train_init, 'val_init': val_init,\n",
        "        'x_batch': x_batch, 'y_batch': y_batch\n",
        "    }\n",
        "    return data\n",
        "\n",
        "\n",
        "def _parse_and_preprocess(example_proto, image_size, augmentation=False):\n",
        "\n",
        "    features = {\n",
        "        'image': tf.FixedLenFeature([], tf.string),\n",
        "        'target': tf.FixedLenFeature([], tf.int64)\n",
        "    }\n",
        "    parsed_features = tf.parse_single_example(example_proto, features)\n",
        "\n",
        "    image = tf.image.decode_jpeg(parsed_features['image'], channels=3)\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    target = parsed_features['target']\n",
        "\n",
        "    if augmentation:\n",
        "        image = tf.image.random_flip_left_right(image)\n",
        "        image = tf.image.random_brightness(image, 0.15)\n",
        "        image = tf.image.random_contrast(image, 0.8, 1.25)\n",
        "        image = tf.image.random_hue(image, 0.1)\n",
        "        image = tf.image.random_saturation(image, 0.8, 1.25)\n",
        "        image = tf.random_crop(image, [image_size, image_size, 3])\n",
        "    else:\n",
        "        image = tf.image.resize_image_with_crop_or_pad(image, image_size, image_size)\n",
        "\n",
        "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
        "    return image, target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lM-Ud1DhJKFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_shufflenet(\n",
        "        initial_lr=1e-2, weight_decay=1e-4,\n",
        "        groups=3, dropout=0.5, complexity_scale_factor=0.75):\n",
        "    \"\"\"Create a ShuffleNet computational graph.\n",
        "    Arguments:\n",
        "        initial_lr: A floar number, initial learning rate.\n",
        "        weight_decay: A floar number, L2 regularization.\n",
        "        groups: An integer, number of groups in group convolutions,\n",
        "            only possible values are: 1, 2, 3, 4, 8.\n",
        "        dropout: A floar number, dropout rate before the last linear layer.\n",
        "        complexity_scale_factor: A floar number, to customize the network\n",
        "            to a desired complexity you can apply a scale factor,\n",
        "            in the original paper they are considering\n",
        "            scale factor values: 0.25, 0.5, 1.0.\n",
        "            It determines the width of the network.\n",
        "    Returns:\n",
        "        graph: A Tensorflow graph.\n",
        "        ops: A dict with ops.\n",
        "    \"\"\"\n",
        "\n",
        "    graph = tf.Graph()\n",
        "    with graph.as_default():\n",
        "\n",
        "        with tf.variable_scope('control'):\n",
        "            # it controls dropout and batch_norm layers\n",
        "            is_training = tf.placeholder_with_default(True, [], 'is_training')\n",
        "\n",
        "        with tf.device('/cpu:0'), tf.variable_scope('input_pipeline'):\n",
        "            data = _get_data(NUM_CLASSES, IMAGE_SIZE)\n",
        "\n",
        "        with tf.variable_scope('inputs'):\n",
        "            X = tf.placeholder_with_default(\n",
        "                data['x_batch'], [None, IMAGE_SIZE, IMAGE_SIZE, 3], 'X'\n",
        "            )\n",
        "            Y = tf.placeholder_with_default(\n",
        "                data['y_batch'], [None, NUM_CLASSES], 'Y'\n",
        "            )\n",
        "\n",
        "        with tf.variable_scope('preprocessing'):\n",
        "            mean = tf.constant([0.485, 0.456, 0.406], tf.float32, [3])\n",
        "            std = tf.constant([0.229, 0.224, 0.225], tf.float32, [3])\n",
        "            # these values are taken from here:\n",
        "            # http://pytorch.org/docs/master/torchvision/models.html,\n",
        "            # but they are not very important, i think.\n",
        "            X -= mean\n",
        "            X /= std\n",
        "\n",
        "        logits = _mapping(\n",
        "            X, is_training, NUM_CLASSES,\n",
        "            groups, dropout, complexity_scale_factor\n",
        "        )\n",
        "\n",
        "        with tf.variable_scope('softmax'):\n",
        "            predictions = tf.nn.softmax(logits)\n",
        "\n",
        "        with tf.variable_scope('log_loss'):\n",
        "            log_loss = tf.losses.softmax_cross_entropy(Y, logits)\n",
        "\n",
        "        with tf.variable_scope('weight_decay'):\n",
        "            _add_weight_decay(weight_decay)\n",
        "\n",
        "        with tf.variable_scope('total_loss'):\n",
        "            total_loss = tf.losses.get_total_loss()\n",
        "\n",
        "        with tf.variable_scope('learning_rate'):\n",
        "            learning_rate = tf.Variable(\n",
        "                initial_lr, trainable=False,\n",
        "                dtype=tf.float32, name='lr'\n",
        "            )\n",
        "            # you can reduce learning rate by some factor, usually 0.1\n",
        "            drop_learning_rate = tf.assign(\n",
        "                learning_rate, LR_REDUCE_FACTOR*learning_rate\n",
        "            )\n",
        "\n",
        "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "        with tf.control_dependencies(update_ops), tf.variable_scope('optimizer'):\n",
        "            optimizer = tf.train.MomentumOptimizer(\n",
        "                learning_rate, momentum=MOMENTUM, use_nesterov=USE_NESTEROV\n",
        "            )\n",
        "            grads_and_vars = optimizer.compute_gradients(total_loss)\n",
        "            optimize = optimizer.apply_gradients(grads_and_vars)\n",
        "\n",
        "        # add histograms of all gradients\n",
        "        grad_summaries = tf.summary.merge(\n",
        "            [tf.summary.histogram(v.name[:-2] + '_grad_hist', g)\n",
        "             for g, v in grads_and_vars]\n",
        "        )\n",
        "\n",
        "        with tf.variable_scope('utilities'):\n",
        "            init_variables = tf.global_variables_initializer()\n",
        "            saver = tf.train.Saver()\n",
        "            is_equal = tf.equal(tf.argmax(predictions, 1), tf.argmax(Y, 1))\n",
        "            accuracy = tf.reduce_mean(tf.cast(is_equal, tf.float32))\n",
        "\n",
        "        summaries = _add_summaries()\n",
        "\n",
        "    graph.finalize()\n",
        "    ops = {\n",
        "        # initialization\n",
        "        'init_variables': init_variables,\n",
        "        'init_data': data['init_data'],\n",
        "        'train_init': data['train_init'],\n",
        "        'val_init': data['val_init'],\n",
        "\n",
        "        # training\n",
        "        'optimize': optimize, 'drop_learning_rate': drop_learning_rate,\n",
        "\n",
        "        # evaluation\n",
        "        'predictions': predictions,\n",
        "        'log_loss': log_loss, 'accuracy': accuracy,\n",
        "        'summaries': summaries, 'grad_summaries': grad_summaries,\n",
        "        'saver': saver\n",
        "    }\n",
        "    return graph, ops\n",
        "\n",
        "\n",
        "def _add_summaries():\n",
        "    \"\"\"Add histograms of all trainable variables.\"\"\"\n",
        "\n",
        "    summaries = []\n",
        "    trainable_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
        "\n",
        "    for v in trainable_vars:\n",
        "        summaries += [tf.summary.histogram(v.name[:-2] + '_hist', v)]\n",
        "\n",
        "    return tf.summary.merge(summaries)\n",
        "\n",
        "\n",
        "def _add_weight_decay(weight_decay):\n",
        "    \"\"\"Add L2 regularization to all trainable kernel weights.\"\"\"\n",
        "\n",
        "    weight_decay = tf.constant(\n",
        "        weight_decay, tf.float32,\n",
        "        [], 'weight_decay'\n",
        "    )\n",
        "\n",
        "    trainable = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
        "    kernels = [v for v in trainable if 'kernel' in v.name]\n",
        "\n",
        "    for K in kernels:\n",
        "        l2_loss = tf.multiply(\n",
        "            weight_decay, tf.nn.l2_loss(K)\n",
        "        )\n",
        "        tf.losses.add_loss(l2_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLJy3hxIOV3F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7b9e7c88-4adc-4078-92c2-b76957864922"
      },
      "source": [
        "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
        "!unzip -qq 'tiny-imagenet-200.zip'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-25 17:24:47--  http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
            "Resolving cs231n.stanford.edu (cs231n.stanford.edu)... 171.64.68.10\n",
            "Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248100043 (237M) [application/zip]\n",
            "Saving to: ‘tiny-imagenet-200.zip’\n",
            "\n",
            "tiny-imagenet-200.z 100%[===================>] 236.61M  16.4MB/s    in 15s     \n",
            "\n",
            "2019-11-25 17:25:03 (15.3 MB/s) - ‘tiny-imagenet-200.zip’ saved [248100043/248100043]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBk_qlp6JJ_j",
        "colab_type": "code",
        "outputId": "ce480f02-d118-47b0-8463-25c513b27cc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "# a folder from tiny-imagenet-200.zip file\n",
        "data_dir = './tiny-imagenet-200/'\n",
        "\n",
        "# load validation metadata\n",
        "annotations_file = os.path.join(data_dir, 'val', 'val_annotations.txt')\n",
        "val_data = pd.read_csv(annotations_file, sep='\\t', header=None)\n",
        "val_data.drop([2, 3, 4, 5], axis=1, inplace=True)  # drop bounding boxes info\n",
        "val_data.columns = ['img_name', 'img_class']\n",
        "unique_classes = val_data.img_class.unique()\n",
        "\n",
        "\n",
        "print('moving validation data')\n",
        "\n",
        "# create new folders to move the data into\n",
        "validation_dir = os.path.join(data_dir, 'validation')\n",
        "os.mkdir(validation_dir)\n",
        "for name in unique_classes:\n",
        "    os.mkdir(os.path.join(validation_dir, name))\n",
        "\n",
        "# loop over all classes\n",
        "for name in tqdm(unique_classes):\n",
        "    # choose images only from a specific class\n",
        "    class_images = val_data.loc[val_data.img_class == name, 'img_name'].values\n",
        "    # copy these images to a new folder\n",
        "    for img in class_images:\n",
        "        shutil.copyfile(\n",
        "            os.path.join(data_dir, 'val', 'images', img),\n",
        "            os.path.join(validation_dir, name, img)\n",
        "        )\n",
        "\n",
        "\n",
        "print('\\nmoving training data')\n",
        "\n",
        "# create new folders to move data into\n",
        "training_dir = os.path.join(data_dir, 'training')\n",
        "os.mkdir(training_dir)\n",
        "for name in unique_classes:\n",
        "    os.mkdir(os.path.join(training_dir, name))\n",
        "\n",
        "# loop over all classes\n",
        "for name in tqdm(unique_classes):\n",
        "    # choose images only from a specific class\n",
        "    class_images = os.listdir(os.path.join(data_dir, 'train', name, 'images'))\n",
        "    # copy these images to a new folder\n",
        "    for img in class_images:\n",
        "        shutil.copyfile(\n",
        "            os.path.join(data_dir, 'train', name, 'images', img),\n",
        "            os.path.join(training_dir, name, img)\n",
        "        )\n",
        "\n",
        "print('\\nvalidation data is in', validation_dir)\n",
        "print('training data is in', training_dir)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  8%|▊         | 16/200 [00:00<00:01, 159.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "moving validation data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:01<00:00, 164.54it/s]\n",
            "  1%|          | 2/200 [00:00<00:10, 18.58it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "moving training data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:11<00:00, 17.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "validation data is in ./tiny-imagenet-200/validation\n",
            "training data is in ./tiny-imagenet-200/training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iirXmylxJJ-e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "c77de163-2e25-4290-fae4-6d09e7b6cbc7"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import os\n",
        "import io\n",
        "\n",
        "\"\"\"The purpose of this script is\n",
        "to convert image dataset that looks like:\n",
        "    class1/image1.jpg\n",
        "    class1/image44.jpg\n",
        "    class1/image546.jpg\n",
        "    ...\n",
        "    class6/image55.jpg\n",
        "    class6/image12.jpg\n",
        "    class6/image76.jpg\n",
        "    ...\n",
        "to tfrecords format.\n",
        "1. It assumes that each folder is separate class and\n",
        "that the number of classes equals to the number of folders.\n",
        "2. Also it assumes that validation and training folders\n",
        "have the same subfolders (the same classes).\n",
        "3. Additionally it outputs 'class_encoder.npy' file\n",
        "that contains dictionary: folder_name -> class_index (integer).\n",
        "\"\"\"\n",
        "!mkdir 'save'\n",
        "\n",
        "train_dir = './tiny-imagenet-200/training/'\n",
        "val_dir = './tiny-imagenet-200/validation/'\n",
        "save_dir = './save/'\n",
        "\n",
        "def main():\n",
        "    encoder = create_encoder(train_dir)\n",
        "    # now you can get a folder's name from a class index\n",
        "\n",
        "    np.save(os.path.join(save_dir, 'class_encoder.npy'), encoder)\n",
        "    convert(train_dir, encoder, os.path.join(save_dir, 'train.tfrecords'))\n",
        "    convert(val_dir, encoder, os.path.join(save_dir, 'val.tfrecords'))\n",
        "\n",
        "    print('\\nCreated two tfrecords files:')\n",
        "    print(os.path.join(save_dir, 'train.tfrecords'))\n",
        "    print(os.path.join(save_dir, 'val.tfrecords'))\n",
        "\n",
        "\n",
        "def _bytes_feature(value):\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "\n",
        "def _int64_feature(value):\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def to_bytes(array):\n",
        "    image = Image.fromarray(array)\n",
        "    tmp = io.BytesIO()\n",
        "    image.save(tmp, format='jpeg')\n",
        "    return tmp.getvalue()\n",
        "\n",
        "\n",
        "def convert(folder, encoder, tfrecords_filename):\n",
        "    \"\"\"Convert a folder with directories of images to tfrecords format.\n",
        "    Arguments:\n",
        "        folder: A path to a folder where directories with images are.\n",
        "        encoder: A dict, folder_name -> integer.\n",
        "        tfrecords_filename: A path where to save tfrecords file.\n",
        "    \"\"\"\n",
        "\n",
        "    images_metadata = collect_metadata(folder, encoder)\n",
        "    writer = tf.python_io.TFRecordWriter(tfrecords_filename)\n",
        "\n",
        "    for _, row in tqdm(images_metadata.iterrows()):\n",
        "\n",
        "        file_path = os.path.join(folder, row.img_path)\n",
        "\n",
        "        # read an image\n",
        "        image = Image.open(file_path)\n",
        "\n",
        "        # convert to an array\n",
        "        array = np.asarray(image, dtype='uint8')\n",
        "\n",
        "        # some images are grayscale\n",
        "        if array.shape[-1] != 3:\n",
        "            array = np.stack([array, array, array], axis=2)\n",
        "\n",
        "        # get class of the image\n",
        "        target = int(row.class_number)\n",
        "\n",
        "        feature = {\n",
        "            'image': _bytes_feature(to_bytes(array)),\n",
        "            'target': _int64_feature(target),\n",
        "        }\n",
        "\n",
        "        example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "        writer.write(example.SerializeToString())\n",
        "\n",
        "    writer.close()\n",
        "\n",
        "\n",
        "def create_encoder(folder):\n",
        "    \"\"\"Encode directories in the folder with integer values.\n",
        "    Values are in the range 0..(n_directories - 1).\n",
        "    Arguments:\n",
        "        folder: A path to a folder where directories with images are.\n",
        "            Each directory - separate class.\n",
        "    Returns:\n",
        "        A dict.\n",
        "    \"\"\"\n",
        "    classes = os.listdir(folder)\n",
        "    encoder = {n: i for i, n in enumerate(classes)}\n",
        "    return encoder\n",
        "\n",
        "\n",
        "def collect_metadata(folder, encoder):\n",
        "    \"\"\"Collect paths to images. Collect their classes.\n",
        "    All paths must be with respect to 'folder'.\n",
        "    Arguments:\n",
        "        folder: A path to a folder where directories with images are.\n",
        "            Each directory - separate class.\n",
        "        encoder: A dict, folder_name -> integer.\n",
        "    Returns:\n",
        "        A pandas dataframe.\n",
        "    \"\"\"\n",
        "\n",
        "    subdirs = list(os.walk(folder))[1:]\n",
        "    metadata = []\n",
        "\n",
        "    for dir_path, _, files in subdirs:\n",
        "        dir_name = dir_path.split('/')[-1]\n",
        "        for file_name in files:\n",
        "            image_metadata = [dir_name, os.path.join(dir_name, file_name)]\n",
        "            metadata.append(image_metadata)\n",
        "\n",
        "    M = pd.DataFrame(metadata)\n",
        "    M.columns = ['class_name', 'img_path']\n",
        "\n",
        "    # encode folder names by integers\n",
        "    M['class_number'] = M.class_name.apply(lambda x: encoder[x])\n",
        "\n",
        "    # shuffle the dataframe\n",
        "    M = M.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    return M\n",
        "\n",
        "main()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100000it [01:42, 975.19it/s]\n",
            "10000it [00:10, 982.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Created two tfrecords files:\n",
            "./save/train.tfrecords\n",
            "./save/val.tfrecords\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKwWC4rQJJ6U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d707baac-7668-4cde-bfe1-0367c4df7ecc"
      },
      "source": [
        "import tensorflow as tf\n",
        "import shutil\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "\n",
        "run =0\n",
        "reset = False\n",
        "train_tfrecords = './save/train.tfrecords'\n",
        "val_tfrecords = './save/val.tfrecords'\n",
        "num_epochs = 40\n",
        "batch_size = 128\n",
        "steps_per_epoch = 500\n",
        "validation_steps = 50\n",
        "lr_patience = 5\n",
        "lr_threshold = 0.01\n",
        "patience = 10\n",
        "threshold = 0.001\n",
        "initial_lr = 0.1\n",
        "weight_decay = 0.005\n",
        "groups = 4\n",
        "dropout = 0.2\n",
        "complexity_scale_factor = 0.5\n",
        "\n",
        "\n",
        "def train():\n",
        "\n",
        "    # folders for logging and saving\n",
        "    dir_to_log = os.path.join('logs', 'run' + str(run))\n",
        "    dir_to_save = os.path.join('saved', 'run' + str(run))\n",
        "\n",
        "    print('\\nTraining logs and summaries will be in', dir_to_log)\n",
        "    print('Saved model will be in', dir_to_save, '\\n')\n",
        "\n",
        "    # create these folders\n",
        "    if reset and os.path.exists(dir_to_log):\n",
        "        shutil.rmtree(dir_to_log)\n",
        "    if reset and os.path.exists(dir_to_save):\n",
        "        shutil.rmtree(dir_to_save)\n",
        "    if not os.path.exists(dir_to_log):\n",
        "        os.makedirs(dir_to_log)\n",
        "    if not os.path.exists(dir_to_save):\n",
        "        os.makedirs(dir_to_save)\n",
        "\n",
        "    # files with losses and config\n",
        "    training_info_file = os.path.join(dir_to_log, 'training_info.txt')\n",
        "    model_config_file = os.path.join(dir_to_log, 'model_config.txt')\n",
        "    print('Training/validation evaluations will be in', training_info_file)\n",
        "    print('Model config will be in', model_config_file, '\\n')\n",
        "\n",
        "    # create the graph and start a session\n",
        "    graph, ops = get_shufflenet(\n",
        "        initial_lr, weight_decay,\n",
        "        groups, dropout,\n",
        "        complexity_scale_factor\n",
        "    )\n",
        "    sess = tf.Session(graph=graph)\n",
        "    writer = tf.summary.FileWriter(dir_to_log, sess.graph)\n",
        "    print('\\nCreated the graph and started a session!')\n",
        "\n",
        "    # check if to continue training or start from scratch\n",
        "    warm = os.path.exists(training_info_file)  # warm start\n",
        "    if warm and not reset:\n",
        "        print('Restoring previously saved model and continuing training.\\n')\n",
        "        initial_epoch = sum(1 for line in open(training_info_file))\n",
        "        try:\n",
        "            ops['saver'].restore(sess, os.path.join(dir_to_save, 'model'))\n",
        "        except:\n",
        "            print('\\nCan\\'t restore the saved model, '\n",
        "                  'maybe architectures don\\'t match.')\n",
        "            sys.exit()\n",
        "    else:\n",
        "        print('Training model from scratch.\\n')\n",
        "        initial_epoch = 1\n",
        "        sess.run(ops['init_variables'])\n",
        "\n",
        "    # initialize data sources\n",
        "    data_dict = {\n",
        "        'input_pipeline/train_file:0': train_tfrecords,\n",
        "        'input_pipeline/val_file:0': val_tfrecords,\n",
        "        'input_pipeline/batch_size:0': batch_size\n",
        "    }\n",
        "    sess.run(ops['init_data'], data_dict)\n",
        "\n",
        "    losses = []  # training info will be collected here\n",
        "    training_epochs = range(\n",
        "        initial_epoch,\n",
        "        initial_epoch + num_epochs\n",
        "    )\n",
        "\n",
        "    # begin training,\n",
        "    # but you can interrupt training by ctrl-c,\n",
        "    # your model will be saved\n",
        "    try:\n",
        "        for epoch in training_epochs:\n",
        "\n",
        "            start_time = time.time()\n",
        "            running_loss, running_accuracy = 0.0, 0.0\n",
        "            sess.run(ops['train_init'])\n",
        "\n",
        "            # at zeroth step also collect metadata and summaries\n",
        "            run_options = tf.RunOptions(\n",
        "                trace_level=tf.RunOptions.FULL_TRACE\n",
        "            )\n",
        "            run_metadata = tf.RunMetadata()\n",
        "\n",
        "            # do epoch's zeroth step\n",
        "            _, batch_loss, batch_accuracy, summary, grad_summary = sess.run([\n",
        "                ops['optimize'], ops['log_loss'], ops['accuracy'],\n",
        "                ops['summaries'], ops['grad_summaries']\n",
        "            ], options=run_options, run_metadata=run_metadata)\n",
        "            running_loss += batch_loss\n",
        "            running_accuracy += batch_accuracy\n",
        "\n",
        "            print('epoch', epoch)\n",
        "            training_steps = tqdm(\n",
        "                range(1, steps_per_epoch),\n",
        "                initial=1, total=steps_per_epoch\n",
        "            )\n",
        "\n",
        "            # main training loop\n",
        "            for step in training_steps:\n",
        "\n",
        "                _, batch_loss, batch_accuracy = sess.run([\n",
        "                    ops['optimize'], ops['log_loss'], ops['accuracy']\n",
        "                ])\n",
        "                running_loss += batch_loss\n",
        "                running_accuracy += batch_accuracy\n",
        "\n",
        "            # evaluate on the validation set\n",
        "            val_loss, val_accuracy = _evaluate(\n",
        "                sess, ops, validation_steps\n",
        "            )\n",
        "            train_loss = running_loss/steps_per_epoch\n",
        "            train_accuracy = running_accuracy/steps_per_epoch\n",
        "\n",
        "            # collect all losses and accuracies\n",
        "            losses += [(\n",
        "                epoch, train_loss, val_loss,\n",
        "                train_accuracy, val_accuracy, time.time() - start_time\n",
        "            )]\n",
        "            writer.add_run_metadata(run_metadata, str(epoch))\n",
        "            writer.add_summary(summary, epoch)\n",
        "            writer.add_summary(grad_summary, epoch)\n",
        "            print('loss: {0:.3f}, val_loss: {1:.3f}, '\n",
        "                  'acc: {2:.3f}, val_acc: {3:.3f}, time: {4:.3f}\\n'.format(*losses[-1][1:]))\n",
        "\n",
        "            # consider a possibility of early stopping\n",
        "            if _is_early_stopping(losses, patience, threshold):\n",
        "                print('Early stopping!')\n",
        "                break\n",
        "\n",
        "            # consider a possibility of reducing learning rate by some factor\n",
        "            _reduce_lr_on_plateau(\n",
        "                sess, ops, losses,\n",
        "                lr_patience, lr_threshold\n",
        "            )\n",
        "    except (KeyboardInterrupt, SystemExit):\n",
        "        print(' Interruption detected, exiting the program...')\n",
        "\n",
        "    sess.close()\n",
        "\n",
        "\n",
        "def _evaluate(sess, ops, validation_steps):\n",
        "\n",
        "    val_loss, val_accuracy = 0.0, 0.0\n",
        "    sess.run(ops['val_init'])\n",
        "\n",
        "    for i in range(validation_steps):\n",
        "        batch_loss, batch_accuracy = sess.run(\n",
        "            [ops['log_loss'], ops['accuracy']],\n",
        "            {'control/is_training:0': False}\n",
        "        )\n",
        "        val_loss += batch_loss\n",
        "        val_accuracy += batch_accuracy\n",
        "\n",
        "    val_loss /= validation_steps\n",
        "    val_accuracy /= validation_steps\n",
        "    return val_loss, val_accuracy\n",
        "\n",
        "\n",
        "# it decides if training must stop\n",
        "def _is_early_stopping(losses, patience=10, threshold=0.01):\n",
        "\n",
        "    # get validation set accuracies\n",
        "    accuracies = [x[4] for x in losses]\n",
        "\n",
        "    if len(losses) > (patience + 4):\n",
        "        # running average\n",
        "        average = (accuracies[-(patience + 4)] +\n",
        "                   accuracies[-(patience + 3)] +\n",
        "                   accuracies[-(patience + 2)] +\n",
        "                   accuracies[-(patience + 1)] +\n",
        "                   accuracies[-patience])/5.0\n",
        "        return accuracies[-1] < average + threshold\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "\n",
        "def _reduce_lr_on_plateau(\n",
        "        sess, ops, losses,\n",
        "        patience=10, threshold=0.01):\n",
        "\n",
        "    # get validation set accuracies\n",
        "    accuracies = [x[4] for x in losses]\n",
        "\n",
        "    if len(losses) > (patience + 4):\n",
        "        # running average\n",
        "        average = (accuracies[-(patience + 4)] +\n",
        "                   accuracies[-(patience + 3)] +\n",
        "                   accuracies[-(patience + 2)] +\n",
        "                   accuracies[-(patience + 1)] +\n",
        "                   accuracies[-patience])/5.0\n",
        "        if accuracies[-1] < (average + threshold):\n",
        "            sess.run(ops['drop_learning_rate'])\n",
        "            print('Learning rate is dropped!\\n')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training logs and summaries will be in logs/run0\n",
            "Saved model will be in saved/run0 \n",
            "\n",
            "Training/validation evaluations will be in logs/run0/training_info.txt\n",
            "Model config will be in logs/run0/model_config.txt \n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_crop is deprecated. Please use tf.image.random_crop instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_image_with_crop_or_pad is deprecated. Please use tf.image.resize_with_crop_or_pad instead.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-3-34000389fd99>:55: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.data.get_output_types(dataset)`.\n",
            "WARNING:tensorflow:From <ipython-input-3-34000389fd99>:56: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.data.get_output_shapes(dataset)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:347: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.data.get_output_types(iterator)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:348: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.data.get_output_shapes(iterator)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py:350: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.data.get_output_classes(iterator)`.\n",
            "WARNING:tensorflow:From <ipython-input-2-5a2c69c5937f>:140: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/normalization.py:327: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From <ipython-input-2-5a2c69c5937f>:129: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "\n",
            "Created the graph and started a session!\n",
            "Training model from scratch.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 1/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:33<00:00,  5.48it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 4.897, val_loss: 4.325, acc: 0.049, val_acc: 0.090, time: 111.937\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:31,  5.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.46it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 4.332, val_loss: 4.210, acc: 0.087, val_acc: 0.103, time: 101.492\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:30,  5.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.47it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 4.191, val_loss: 4.128, acc: 0.103, val_acc: 0.113, time: 101.789\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:29,  5.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.46it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 4.148, val_loss: 4.233, acc: 0.110, val_acc: 0.103, time: 101.815\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:30,  5.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.43it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 4.101, val_loss: 4.120, acc: 0.115, val_acc: 0.115, time: 102.095\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:30,  5.49it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.41it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 4.083, val_loss: 4.006, acc: 0.119, val_acc: 0.133, time: 102.071\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:31,  5.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.45it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 4.058, val_loss: 4.082, acc: 0.123, val_acc: 0.120, time: 101.952\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:30,  5.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.51it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 4.049, val_loss: 3.910, acc: 0.121, val_acc: 0.148, time: 101.888\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:32,  5.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.47it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 4.047, val_loss: 4.001, acc: 0.126, val_acc: 0.137, time: 101.898\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:30,  5.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.48it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 4.032, val_loss: 4.114, acc: 0.125, val_acc: 0.107, time: 101.784\n",
            "\n",
            "Learning rate is dropped!\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:31,  5.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.48it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 3.489, val_loss: 3.245, acc: 0.212, val_acc: 0.250, time: 101.503\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:32,  5.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.52it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 3.287, val_loss: 3.133, acc: 0.246, val_acc: 0.270, time: 101.586\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:30,  5.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.45it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 3.214, val_loss: 3.090, acc: 0.259, val_acc: 0.288, time: 101.879\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:30,  5.52it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.41it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 3.163, val_loss: 3.058, acc: 0.267, val_acc: 0.290, time: 102.000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:32,  5.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.45it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 3.114, val_loss: 3.030, acc: 0.277, val_acc: 0.290, time: 102.106\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:31,  5.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.47it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 3.066, val_loss: 2.982, acc: 0.287, val_acc: 0.301, time: 102.036\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:31,  5.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.44it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 3.033, val_loss: 3.017, acc: 0.294, val_acc: 0.296, time: 102.081\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:31,  5.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 18\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.43it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 3.005, val_loss: 2.950, acc: 0.299, val_acc: 0.311, time: 102.128\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:31,  5.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.48it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 2.973, val_loss: 2.956, acc: 0.303, val_acc: 0.310, time: 101.987\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:31,  5.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.44it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 2.945, val_loss: 2.897, acc: 0.310, val_acc: 0.324, time: 101.946\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:30,  5.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.45it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 2.917, val_loss: 2.878, acc: 0.315, val_acc: 0.318, time: 101.940\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:33,  5.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 22\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.47it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 2.890, val_loss: 2.831, acc: 0.322, val_acc: 0.338, time: 101.892\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:32,  5.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 23\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.44it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 2.870, val_loss: 2.818, acc: 0.326, val_acc: 0.336, time: 102.045\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:31,  5.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.45it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 2.854, val_loss: 2.848, acc: 0.327, val_acc: 0.331, time: 102.115\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:30,  5.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.46it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 2.833, val_loss: 2.816, acc: 0.333, val_acc: 0.337, time: 102.016\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:31,  5.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 26\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.45it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 2.823, val_loss: 2.794, acc: 0.333, val_acc: 0.336, time: 102.140\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:31,  5.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 27\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.45it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 2.798, val_loss: 2.788, acc: 0.339, val_acc: 0.340, time: 102.133\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:31,  5.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 28\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.44it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 2.798, val_loss: 2.787, acc: 0.339, val_acc: 0.344, time: 102.058\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:32,  5.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 29\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.50it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 2.788, val_loss: 2.787, acc: 0.341, val_acc: 0.341, time: 101.546\n",
            "\n",
            "Learning rate is dropped!\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:31,  5.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.46it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 2.471, val_loss: 2.448, acc: 0.412, val_acc: 0.416, time: 102.049\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:31,  5.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 31\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.45it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 2.367, val_loss: 2.409, acc: 0.432, val_acc: 0.422, time: 101.850\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:31,  5.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.47it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 2.316, val_loss: 2.402, acc: 0.443, val_acc: 0.430, time: 101.775\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:32,  5.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 33\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.43it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 2.278, val_loss: 2.410, acc: 0.451, val_acc: 0.422, time: 102.257\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:30,  5.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 34\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.42it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 2.266, val_loss: 2.371, acc: 0.453, val_acc: 0.429, time: 102.119\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:29,  5.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 35\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.45it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 2.241, val_loss: 2.384, acc: 0.460, val_acc: 0.432, time: 102.071\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:31,  5.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 36\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.42it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 2.227, val_loss: 2.356, acc: 0.463, val_acc: 0.437, time: 102.129\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:31,  5.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 37\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.49it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 2.210, val_loss: 2.340, acc: 0.465, val_acc: 0.437, time: 101.919\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:35,  5.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 38\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.44it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 2.199, val_loss: 2.342, acc: 0.468, val_acc: 0.439, time: 102.029\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:30,  5.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 39\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.51it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 2.191, val_loss: 2.336, acc: 0.470, val_acc: 0.439, time: 101.982\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:00<01:32,  5.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 40\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [01:31<00:00,  5.45it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 2.178, val_loss: 2.357, acc: 0.472, val_acc: 0.438, time: 101.685\n",
            "\n",
            "Learning rate is dropped!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyMhShu8JJri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}